{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Selection\n",
    "\n",
    "This notebook serves to attempt to tune multiple regression models for use in combination \n",
    "with pykrige RegressionKriging(). To this end it contains a custom k-fold grid search based\n",
    "tuning class. Subsequent section contain training/tuning for several different models. \n",
    "The final section provides an overview of model performance and optimal parameters found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The first code cell can be edited to define file locations and adjust model in-/outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nodes_input_path = '..\\\\output\\\\final_data_nodes.GEOJSON'\n",
    "\n",
    "x_cols = ['maxspeed', 'bridge', 'junction', 'building_height',\n",
    "          'dist_to_train', 'dist_to_recreation', 'landuse_is_residential', \n",
    "          'landuse_is_commercial', 'landuse_is_industrial', 'rt_highway', \n",
    "          'rt_trunk', 'rt_primary', 'rt_secondary','rt_tertiary', \n",
    "          'rt_unclassified', 'rt_residential', 'rt_living_street',\n",
    "          'rt_busway', 'rt_service',]\n",
    "y_col = 'dBA_reg_adj'\n",
    "c_cols = ['x', 'y']\n",
    "random_seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default libs\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# vector geo data libs\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# kriging\n",
    "from pykrige.rk import RegressionKriging\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "from itertools import product\n",
    "import re\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "gdf = gpd.read_file(data_nodes_input_path, engine='pyogrio')\n",
    "# Retain only data relevant to training/testing\n",
    "gdf = gdf[gdf[y_col].notna()]\n",
    "\n",
    "# Utilities for retrieving x/y/coordinate arrays\n",
    "def get_x_arr(df, cols=x_cols):\n",
    "    return df[cols].values\n",
    "def get_y_arr(df, col=y_col):\n",
    "    return df[col].values\n",
    "def get_c_arr(df, cols=c_cols):\n",
    "    return df[cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyKrige Tuning Setup\n",
    "This section contains the custom tuner class (and dependencies). The second cell defines utilities creating spatial folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "class pykrige_tuning_results(): #todo update to accept list of tuning_score objs\n",
    "    def __init__(self, score_overview, model):\n",
    "        # score_overview = dict(sorted(score_overview.items(), key=lambda s: s[1]))\n",
    "        self.score_overview = score_overview\n",
    "        self.best_iteration = sorted(score_overview, key=(lambda o: o.score))[0]\n",
    "        # self.best_score = best_iteration.score        \n",
    "        # self.best_model_params = list(score_overview.keys())[0][0]\n",
    "        # self.best_model_params = self._recover_param_dict(self.best_model_params)\n",
    "        # self.best_krige_params = list(score_overview.keys())[0][1]\n",
    "        # self.best_krige_params = self._recover_param_dict(self.best_krige_params)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def get_optimal_model(self):\n",
    "        m = self.model(**self.best_iteration.model_params)\n",
    "        rk_m = RegressionKriging(m, **self.best_iteration.krige_params)\n",
    "        return rk_m\n",
    "        \n",
    "class tuning_score():\n",
    "    def __init__(self, model_params, krige_params, score):\n",
    "        self.model_params = model_params\n",
    "        self.krige_params = krige_params\n",
    "        self.score = score\n",
    "\n",
    "class pykrige_rk_tuner():\n",
    "    \"\"\"\n",
    "    Provides an adapted kfold-tuning routine for use with pykrige. Makes several\n",
    "    assumptions likely specific to this application.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, x_cols, y_col, c_cols=['x', 'y'], fold_col='fold', scorer=root_mean_squared_error):\n",
    "        self.data = data\n",
    "        self.x_cols = x_cols\n",
    "        self.y_col = y_col\n",
    "        self.c_cols = c_cols\n",
    "        self.scorer = scorer\n",
    "        self.fold_col = fold_col\n",
    "\n",
    "        self.fold_values = self.data[self.fold_col].unique()\n",
    "\n",
    "    def _create_fold_arr(self, sorted_df, no_folds):\n",
    "        fold_arr = np.concatenate([np.full((sorted_df.shape[0] // no_folds), i) for i in range(no_folds-1)])\n",
    "        fold_arr = np.concatenate((fold_arr, np.full(sorted_df.shape[0]-len(fold_arr), no_folds-1)))\n",
    "        return fold_arr\n",
    "\n",
    "    def _create_folds(self, no_of_folds=16):\n",
    "        # no_of_folds must be the square of some integer (i.e. 1,4,9,16,...)\n",
    "        self.data = self.sort_values(by=['x', 'y']).reset_index(drop=True)\n",
    "        self.data['xf'] = self._create_fold_arr(self.data, np.sqrt(no_of_folds))\n",
    "        self.data = self.sort_values(by=['xf', 'y']).reset_index(drop=True)\n",
    "        self.data['fold'] = self._create_fold_arr(self.data, no_of_folds)\n",
    "        del self.data['xf']\n",
    "\n",
    "    def _create_param_dicts_from_grid(self, grid):\n",
    "        keys = grid.keys()\n",
    "        values = grid.values()\n",
    "        combinations = list(product(*values))\n",
    "        return [dict(zip(keys, combination)) for combination in combinations]\n",
    "    \n",
    "    def set_scorer(self, scorer):\n",
    "        self.scorer = scorer\n",
    "\n",
    "    def tune(self, model, model_param_grid, krige_param_grid, verbose=False):\n",
    "        \"\"\"Custom tuning function for pykrige\n",
    "        \n",
    "        args:\n",
    "        ----------\n",
    "        model: \n",
    "            ML model from sklearn (as per pykrige docs)\n",
    "        model_param_grid: \n",
    "            A dict with (k,v)=(parameter_name:[param_values]), with parameters for the sklearn model. \n",
    "            Each possible combination is tested.\n",
    "        krige_param_grid: \n",
    "            A dict with (k,v)=(parameter_name:[param_values]), with parameters for the regression kriging model. \n",
    "            Each possible combination is tested.\n",
    "        \"\"\"\n",
    "        model_param_dicts = self._create_param_dicts_from_grid(model_param_grid) \n",
    "        krige_param_dicts = self._create_param_dicts_from_grid(krige_param_grid)\n",
    "        score_tracker = []\n",
    "\n",
    "        tq = tqdm(total=len(model_param_dicts)*len(krige_param_dicts))\n",
    "        for m_params in model_param_dicts:\n",
    "            for k_params in krige_param_dicts:\n",
    "                if verbose: print(m_params, k_params)\n",
    "                scores = []\n",
    "                for fold in self.fold_values: \n",
    "                    X_train = self.data[self.data[self.fold_col] != fold][self.x_cols].values\n",
    "                    c_train = self.data[self.data[self.fold_col] != fold][self.c_cols].values\n",
    "                    y_train = self.data[self.data[self.fold_col] != fold][self.y_col].values\n",
    "\n",
    "                    X_test = self.data[self.data[self.fold_col] == fold][self.x_cols].values\n",
    "                    c_test = self.data[self.data[self.fold_col] == fold][self.c_cols].values\n",
    "                    y_test = self.data[self.data[self.fold_col] == fold][self.y_col].values\n",
    "                    \n",
    "                    m = model(**m_params)\n",
    "                    m_rk = RegressionKriging(regression_model=m, verbose=False, **k_params)\n",
    "                    with HiddenPrints():\n",
    "                        m_rk.fit(X_train, c_train, y_train)\n",
    "                    y_pred = m_rk.predict(X_test, c_test)\n",
    "                    scores.append(self.scorer(y_pred, y_test))\n",
    "                \n",
    "                score_tracker.append(tuning_score(m_params, k_params, np.mean(scores)))\n",
    "                    #[(str(m_params.items()), str(k_params.items()))] = np.mean(scores)\n",
    "                tq.update()\n",
    "                    \n",
    "        return pykrige_tuning_results(score_tracker, model)\n",
    "        # score_overview = dict(sorted(score_overview.items(), key=lambda s: s[1]))\n",
    "        # self.score_overview = score_overview\n",
    "        # self.best_score = list(score_overview.values())[0]\n",
    "        # self.best_model_params = list(score_overview.keys())[0][0]\n",
    "        # self.best_krige_params = list(score_overview.keys())[0][1]\n",
    "    \n",
    "    # def train_model(self, model):\n",
    "    #     if not self.best_model_params: Throw\n",
    "    #     if not self.best_krige_params: Throw\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial fold utils\n",
    "\n",
    "\n",
    "def create_spatial_folds(df, no_of_folds=16):\n",
    "\n",
    "    def create_fold_arr(sorted_df, no_folds):\n",
    "        fold_arr = np.concatenate([np.full((sorted_df.shape[0] // no_folds), i) for i in range(no_folds-1)])\n",
    "        fold_arr = np.concatenate((fold_arr, np.full(sorted_df.shape[0]-len(fold_arr), no_folds-1)))\n",
    "        return fold_arr\n",
    "    # no_of_folds must be the square of some integer (i.e. 1,4,9,16,...)\n",
    "    df = df.sort_values(by=['x', 'y']).reset_index(drop=True)\n",
    "    df['xf'] = create_fold_arr(df, int(np.sqrt(no_of_folds)))\n",
    "    df = df.sort_values(by=['xf', 'y']).reset_index(drop=True)\n",
    "    return create_fold_arr(df, no_of_folds)\n",
    "\n",
    "def spatial_train_test_split(gdf, no_test_folds, random_state=1, fold_col='fold'):\n",
    "    \"\"\"\n",
    "    spatial folds\n",
    "    \"\"\"\n",
    "    random.seed(random_state)\n",
    "    folds = gdf[fold_col].unique()\n",
    "    random.shuffle(folds)\n",
    "    return gdf[gdf[fold_col].isin(folds[:no_test_folds])], gdf[gdf[fold_col].isin(folds[no_test_folds:])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * setup\n",
    "score_overview_df = pd.DataFrame(data={'model': [],\n",
    "                                      'RMSE base': [],\n",
    "                                      'R2 base': [],\n",
    "                                      'RMSE tuned': [],\n",
    "                                      'R2 tuned': [],})\n",
    "\n",
    "# utility to get the scores\n",
    "def get_scores_for_m(m, train, test):\n",
    "    if isinstance(m, RegressionKriging):\n",
    "        km = m\n",
    "    else:\n",
    "        try: \n",
    "            km = RegressionKriging(m)\n",
    "        except:\n",
    "            raise ValueError('get_scores_for_m() function must be provided with either a regression or a regressionkriging model.')\n",
    "    \n",
    "    km.fit(get_x_arr(train), get_c_arr(train), get_y_arr(train))\n",
    "    y_pred = km.predict(get_x_arr(test),\n",
    "                        get_c_arr(test))\n",
    "    r2 = r2_score(get_y_arr(test), y_pred)\n",
    "    rmse = root_mean_squared_error(get_y_arr(test), y_pred)\n",
    "    return r2, rmse\n",
    "\n",
    "\n",
    "# Defining spatial folds\n",
    "gdf['fold'] = create_spatial_folds(gdf, 16)\n",
    "gdf_train, gdf_test = spatial_train_test_split(gdf, 4, random_state=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "# Regression kriging parameters to tune\n",
    "rk_param_grid = {\n",
    "    'n_closest_points': [20, 30] ,\n",
    "    'nlags': [3, 6, 9] # unimportant in testing\n",
    "}\n",
    "\n",
    "x_cols2 = ['maxspeed', 'bridge', 'junction', 'building_height',\n",
    "          'dist_to_train', 'dist_to_recreation']#, 'landuse_is_residential', \n",
    "        #   'landuse_is_commercial', 'landuse_is_industrial']\n",
    "# Regression kriging tuner\n",
    "rk_tuner = pykrige_rk_tuner(data=gdf_train,\n",
    "                            x_cols=x_cols2,\n",
    "                            y_col=y_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "print(sorted([1,3,2,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c79f34a73747caad5ab6bdc6e8e9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    }
   ],
   "source": [
    "# pre tuning scores\n",
    "m = LinearRegression\n",
    "r2_base, rmse_base = get_scores_for_m(m(), gdf_train, gdf_test)\n",
    "\n",
    "# tuning\n",
    "ols_param_grid = {}\n",
    "ols_tune_results = rk_tuner.tune(m, ols_param_grid, rk_param_grid)\n",
    "\n",
    "# post tuning scores\n",
    "r2_tuned, rmse_tuned = get_scores_for_m(ols_tune_results.get_optimal_model(),\n",
    "                                        gdf_train, gdf_test)\n",
    "\n",
    "# scoring evaluations, discarding unnecessary vars\n",
    "score_overview_df.loc[score_overview_df.shape[0]] = \\\n",
    "    [m().__class__.__name__, rmse_base, r2_base, rmse_tuned, r2_tuned]\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b072373e1aa5416c81e74793e4aef18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    }
   ],
   "source": [
    "# pre tuning scores\n",
    "m = RandomForestRegressor\n",
    "r2_base, rmse_base = get_scores_for_m(m(random_state=random_seed), gdf_train, gdf_test)\n",
    "\n",
    "# tuning\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [2,4,6,8,10],\n",
    "    'random_state':[random_seed]\n",
    "}\n",
    "rf_tune_results = rk_tuner.tune(m, rf_param_grid, rk_param_grid)\n",
    "\n",
    "# post tuning scores\n",
    "r2_tuned, rmse_tuned = get_scores_for_m(rf_tune_results.get_optimal_model(),\n",
    "                                        gdf_train, gdf_test)\n",
    "\n",
    "# scoring evaluations, discarding unnecessary vars\n",
    "score_overview_df.loc[score_overview_df.shape[0]] = \\\n",
    "    [m().__class__.__name__, rmse_base, r2_base, rmse_tuned, r2_tuned]\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting - gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f914e404fef14b2cb8287be1ee2ba4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    }
   ],
   "source": [
    "# pre tuning scores\n",
    "m = GradientBoostingRegressor\n",
    "r2_base, rmse_base = get_scores_for_m(m(random_state=random_seed), gdf_train, gdf_test)\n",
    "\n",
    "# tuning\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [2,4,6,8,10],\n",
    "    'random_state':[random_seed]\n",
    "}\n",
    "gb_tune_results = rk_tuner.tune(m, gb_param_grid, rk_param_grid)\n",
    "\n",
    "# post tuning scores\n",
    "r2_tuned, rmse_tuned = get_scores_for_m(gb_tune_results.get_optimal_model(),\n",
    "                                        gdf_train, gdf_test)\n",
    "\n",
    "# scoring evaluations, discarding unnecessary vars\n",
    "score_overview_df.loc[score_overview_df.shape[0]] = \\\n",
    "    [m().__class__.__name__, rmse_base, r2_base, rmse_tuned, r2_tuned]\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianProcessRegressor - gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n",
      "pre-tuned eval done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\pykrige\\ok.py:753: LinAlgWarning: Ill-conditioned matrix (rcond=2.61538e-19): result may not be accurate.\n",
      "  x = scipy.linalg.solve(a, b)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\pykrige\\ok.py:753: LinAlgWarning: Ill-conditioned matrix (rcond=2.61539e-19): result may not be accurate.\n",
      "  x = scipy.linalg.solve(a, b)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\pykrige\\ok.py:753: LinAlgWarning: Ill-conditioned matrix (rcond=1.74359e-19): result may not be accurate.\n",
      "  x = scipy.linalg.solve(a, b)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\pykrige\\ok.py:753: LinAlgWarning: Ill-conditioned matrix (rcond=1.96154e-19): result may not be accurate.\n",
      "  x = scipy.linalg.solve(a, b)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\pykrige\\ok.py:753: LinAlgWarning: Ill-conditioned matrix (rcond=1.10651e-18): result may not be accurate.\n",
      "  x = scipy.linalg.solve(a, b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203c258cf8ef4f2c8131dd40b3f6d7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\flori\\!projects\\noise-these\\noise-thesis\\.venv\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    }
   ],
   "source": [
    "# pre tuning scores\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "m = GaussianProcessRegressor\n",
    "r2_base, rmse_base = get_scores_for_m(m(random_state=random_seed), gdf_train, gdf_test)\n",
    "print('pre-tuned eval done')\n",
    "import time\n",
    "time.sleep(3)\n",
    "# tuning\n",
    "param_grid = {\n",
    "    'kernel': [\n",
    "        RBF(length_scale=1.0),\n",
    "        RBF(length_scale=0.1),\n",
    "        Matern(length_scale=1.0, nu=1.5),\n",
    "        Matern(length_scale=0.1, nu=1.5),\n",
    "        RationalQuadratic(length_scale=1.0, alpha=1.0),\n",
    "        RationalQuadratic(length_scale=0.1, alpha=1.0),\n",
    "        WhiteKernel()\n",
    "    ],\n",
    "    'alpha': [1e-7, 1e-4, 1e-2, 1e-1],\n",
    "    'n_restarts_optimizer': [0, 1, 5]\n",
    "}\n",
    "sgd_tune_results = rk_tuner.tune(m, param_grid, rk_param_grid)\n",
    "\n",
    "# post tuning scores\n",
    "r2_tuned, rmse_tuned = get_scores_for_m(sgd_tune_results.get_optimal_model(),\n",
    "                                        gdf_train, gdf_test)\n",
    "\n",
    "# # scoring evaluations, discarding unnecessary vars\n",
    "score_overview_df.loc[score_overview_df.shape[0]] = \\\n",
    "    [m().__class__.__name__, rmse_base, r2_base, rmse_tuned, r2_tuned]\n",
    "del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished learning regression model\n",
      "Finished kriging residuals\n"
     ]
    }
   ],
   "source": [
    "r2_tuned, rmse_tuned = get_scores_for_m(sgd_tune_results.get_optimal_model(),\n",
    "                                        gdf_train, gdf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional pickling function to save tuning results:\n",
    "\"\"\"import pickle\n",
    "with open('ols_dump', 'wb') as f:\n",
    "    pickle.dump(ols_tune_results, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE base</th>\n",
       "      <th>R2 base</th>\n",
       "      <th>RMSE tuned</th>\n",
       "      <th>R2 tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCMeta</td>\n",
       "      <td>6.572276</td>\n",
       "      <td>-0.794307</td>\n",
       "      <td>6.532011</td>\n",
       "      <td>-0.772389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCMeta</td>\n",
       "      <td>5.065892</td>\n",
       "      <td>-0.066049</td>\n",
       "      <td>4.715172</td>\n",
       "      <td>0.076450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCMeta</td>\n",
       "      <td>5.135535</td>\n",
       "      <td>-0.095561</td>\n",
       "      <td>4.777596</td>\n",
       "      <td>0.051835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>67.658090</td>\n",
       "      <td>-189.153625</td>\n",
       "      <td>4.953920</td>\n",
       "      <td>-0.019443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  RMSE base     R2 base  RMSE tuned  R2 tuned\n",
       "0  ABCMeta   6.572276   -0.794307    6.532011 -0.772389\n",
       "1  ABCMeta   5.065892   -0.066049    4.715172  0.076450\n",
       "2  ABCMeta   5.135535   -0.095561    4.777596  0.051835\n",
       "3     type  67.658090 -189.153625    4.953920 -0.019443"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score overview graph\n",
    "score_overview_df.to_clipboard()\n",
    "score_overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>paramater</th>\n",
       "      <th>value range</th>\n",
       "      <th>optimal value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>[50, 100, 200]</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>max_depth</td>\n",
       "      <td>[None, 10, 20, 30]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>[2, 5, 10]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>max_features</td>\n",
       "      <td>[2, 4, 6, 8, 10]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gdb</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>[50, 100, 200]</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>[0.01, 0.1, 0.2, 0.3]</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>max_depth</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>[2, 5, 10]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>max_features</td>\n",
       "      <td>[2, 4, 6, 8, 10]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpr</td>\n",
       "      <td>kernel</td>\n",
       "      <td>[RBF(length_scale=1), RBF(length_scale=0.1), M...</td>\n",
       "      <td>WhiteKernel(noise_level=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>alpha</td>\n",
       "      <td>[1e-07, 0.0001, 0.01, 0.1]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>n_restarts_optimizer</td>\n",
       "      <td>[0, 1, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model             paramater  \\\n",
       "0     rf          n_estimators   \n",
       "1                    max_depth   \n",
       "2            min_samples_split   \n",
       "3             min_samples_leaf   \n",
       "4                 max_features   \n",
       "5    gdb          n_estimators   \n",
       "6                learning_rate   \n",
       "7                    max_depth   \n",
       "8            min_samples_split   \n",
       "9             min_samples_leaf   \n",
       "10                max_features   \n",
       "11   gpr                kernel   \n",
       "12                       alpha   \n",
       "13        n_restarts_optimizer   \n",
       "\n",
       "                                          value range  \\\n",
       "0                                      [50, 100, 200]   \n",
       "1                                  [None, 10, 20, 30]   \n",
       "2                                          [2, 5, 10]   \n",
       "3                                           [1, 2, 4]   \n",
       "4                                    [2, 4, 6, 8, 10]   \n",
       "5                                      [50, 100, 200]   \n",
       "6                               [0.01, 0.1, 0.2, 0.3]   \n",
       "7                                           [3, 5, 7]   \n",
       "8                                          [2, 5, 10]   \n",
       "9                                           [1, 2, 4]   \n",
       "10                                   [2, 4, 6, 8, 10]   \n",
       "11  [RBF(length_scale=1), RBF(length_scale=0.1), M...   \n",
       "12                         [1e-07, 0.0001, 0.01, 0.1]   \n",
       "13                                          [0, 1, 5]   \n",
       "\n",
       "                 optimal value  \n",
       "0                           50  \n",
       "1                           10  \n",
       "2                           10  \n",
       "3                            4  \n",
       "4                            2  \n",
       "5                           50  \n",
       "6                         0.01  \n",
       "7                            7  \n",
       "8                           10  \n",
       "9                            2  \n",
       "10                           2  \n",
       "11  WhiteKernel(noise_level=1)  \n",
       "12                         0.0  \n",
       "13                           0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Param overview graph\n",
    "models = []\n",
    "param_names = []\n",
    "param_vals = []\n",
    "param_opts = []\n",
    "for name, params, results in [('ols', ols_param_grid, ols_tune_results), ('rf', rf_param_grid, rf_tune_results), ('gdb', gb_param_grid, gb_tune_results), ('gpr', param_grid, sgd_tune_results)]:\n",
    "    for i, (param, vals) in enumerate(params.items()):\n",
    "        if param == 'random_state': continue\n",
    "        if i == 0: models.append(name)\n",
    "        else: models.append('')\n",
    "\n",
    "        param_names.append(param)\n",
    "        param_vals.append(vals)\n",
    "        param_opts.append(results.best_iteration.model_params[param])\n",
    "\n",
    "pd.DataFrame(data={'model': models, 'paramater': param_names, 'value range': param_vals, 'optimal value': param_opts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
